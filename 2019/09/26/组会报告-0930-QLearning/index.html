<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  <title>组会报告-0930-QLearning | Rock-Blog</title>
  <meta name="keywords" content=" 深度学习 , 强化学习 , 组会报告 ">
  <meta name="description" content="组会报告-0930-QLearning | Rock-Blog">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="description" content="A*算法的总结，不理解原理可以直接看下方原博客 根据https://www.cnblogs.com/21207-iHome/p/6048969.html">
<meta name="keywords" content="AI,数学,编程">
<meta property="og:type" content="article">
<meta property="og:title" content="A*_algorithm">
<meta property="og:url" content="http://rock-blog.top/2020/06/08/A-algorithm/index.html">
<meta property="og:site_name" content="Rock-Blog">
<meta property="og:description" content="A*算法的总结，不理解原理可以直接看下方原博客 根据https://www.cnblogs.com/21207-iHome/p/6048969.html">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://rock-blog.top/2020/06/08/A-algorithm/pic1.png">
<meta property="og:updated_time" content="2020-06-08T07:12:03.443Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A*_algorithm">
<meta name="twitter:description" content="A*算法的总结，不理解原理可以直接看下方原博客 根据https://www.cnblogs.com/21207-iHome/p/6048969.html">
<meta name="twitter:image" content="http://rock-blog.top/2020/06/08/A-algorithm/pic1.png">


<link rel="icon" href="/img/avatar.jpg">

<link href="/css/style.css?v=1.0.1" rel="stylesheet">

<link href="/css/hl_theme/atom-light.css?v=1.0.1" rel="stylesheet">

<link href="//cdn.bootcss.com/animate.css/3.5.2/animate.min.css" rel="stylesheet">
<link href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="/js/jquery.autocomplete.min.js?v=1.0.1"></script>

<script src="//cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
<script>
    hljs.initHighlightingOnLoad();
</script>

<script src="//cdn.bootcss.com/nprogress/0.2.0/nprogress.min.js"></script>



<script src="//cdn.bootcss.com/jquery-cookie/1.4.1/jquery.cookie.min.js"></script>

<script src="/js/iconfont.js?v=1.0.1"></script>

</head>
<div style="display: none">
  <input class="theme_disqus_on" value="false">
  <input class="theme_preload_comment" value="true">
  <input class="theme_blog_path" value>
</div>

<body>
<aside class="nav">
    <div class="nav-left">
        <a href="/" class="avatar_target">
    <img class="avatar" src="/img/avatar.jpg">
</a>
<div class="author">
    <span>Rock</span>
</div>

<div class="icon">
    
        
        <a title="github" href="https://github.com/guobaoyo" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-github"/>
                </svg>
            
        </a>
        
    
        
        <a title="email" href="mailto:1415500736@qq.com" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-email"/>
                </svg>
            
        </a>
        
    
        
        <a title="qq" href="http://wpa.qq.com/msgrd?v=3&uin=1415500736&site=qq&menu=yes" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-qq"/>
                </svg>
            
        </a>
        
    
        
        <a title="neteasemusic" href="https://music.163.com/#/user/home?id=280020740" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-neteasemusic"/>
                </svg>
            
        </a>
        
    
</div>




<ul>
    <li><div class="all active">全部文章<small>(20)</small></div></li>
    
        
            
            <li><div data-rel="三省吾身">三省吾身<small>(4)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="强化学习">强化学习<small>(2)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="AI">AI<small>(6)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="编程">编程<small>(4)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="数学">数学<small>(2)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="组会报告">组会报告<small>(1)</small></div>
                
            </li>
            
        
    
</ul>
<div class="left-bottom">
    <div class="menus">
    
    
    
    
    </div>
    <div><a class="friends">友链</a></div>
</div>
<input type="hidden" id="yelog_site_posts_number" value="20">

<div style="display: none">
    <span id="busuanzi_value_site_uv"></span>
    <span id="busuanzi_value_site_pv"></span>
</div>

    </div>
    <div class="nav-right">
        <div class="friends-area">
    <div class="friends-title">
        友情链接
        <i class="back-title-list"></i>
    </div>
    <div class="friends-content">
        <ul>
            
            <li><a target="_blank" href="http://yelog.org/">叶落阁</a></li>
            
            <li><a target="_blank" href="http://zivblog.top">王金锋</a></li>
            
            <li><a target="_blank" href="http://yearing1017.cn/">进哥</a></li>
            
        </ul>
    </div>
</div>
        <div class="title-list">
    <form onkeydown="if(event.keyCode==13){return false;}">
        <input class="search" type="text" placeholder="以 in: 开头进行全文搜索" autocomplete="off" id="local-search-input">
        <i class="cross"></i>
        <span>
            <label for="tagswitch">Tags:</label>
            <input id="tagswitch" type="checkbox" style="display: none">
            <i id="tagsWitchIcon"></i>
        </span>
    </form>
    <div class="tags-list">
    
    <li class="article-tag-list-item">
        <a href="javascript:" class="color5">三省吾身</a>
    </li>
    
    <li class="article-tag-list-item">
        <a href="javascript:" class="color3">AI</a>
    </li>
    
    <li class="article-tag-list-item">
        <a href="javascript:" class="color3">数学</a>
    </li>
    
    <li class="article-tag-list-item">
        <a href="javascript:" class="color3">编程</a>
    </li>
    
    <li class="article-tag-list-item">
        <a href="javascript:" class="color5">深度学习</a>
    </li>
    
    <li class="article-tag-list-item">
        <a href="javascript:" class="color3">CV</a>
    </li>
    
    <li class="article-tag-list-item">
        <a href="javascript:" class="color2">python</a>
    </li>
    
    <li class="article-tag-list-item">
        <a href="javascript:" class="color5">强化学习</a>
    </li>
    
    <li class="article-tag-list-item">
        <a href="javascript:" class="color3">go</a>
    </li>
    
    <li class="article-tag-list-item">
        <a href="javascript:" class="color5">技术小结</a>
    </li>
    
    <li class="article-tag-list-item">
        <a href="javascript:" class="color5">组会报告</a>
    </li>
    
    <li class="article-tag-list-item">
        <a href="javascript:" class="color3">考研</a>
    </li>
    
    <li class="article-tag-list-item">
        <a href="javascript:" class="color4">NLP</a>
    </li>
    
    <div class="clearfix"></div>
</div>

    
    <div id="local-search-result">

    </div>
    
    <nav id="title-list-nav">
        
        <a class="三省吾身 " href="/2019/07/08/20190708日记/" data-tag="三省吾身,AI,数学" data-author>
            <span class="post-title" title="20190708日记">20190708日记</span>
            <span class="post-date" title="2019-07-08 19:43:26">2019/07/08</span>
        </a>
        
        <a class="强化学习 " href="/2020/06/08/A-algorithm/" data-tag="AI,数学,编程" data-author>
            <span class="post-title" title="A*_algorithm">A*_algorithm</span>
            <span class="post-date" title="2020-06-08 21:25:01">2020/06/08</span>
        </a>
        
        <a class="AI " href="/2019/05/08/DLwithPython/" data-tag="深度学习,CV,python" data-author>
            <span class="post-title" title="DeepLearning with Python">DeepLearning with Python</span>
            <span class="post-date" title="2019-05-08 17:54:01">2019/05/08</span>
        </a>
        
        <a class="三省吾身 " href="/2019/04/29/DLwords/" data-tag="AI,深度学习" data-author>
            <span class="post-title" title="DLwords">DLwords</span>
            <span class="post-date" title="2019-04-29 19:17:39">2019/04/29</span>
        </a>
        
        <a class="强化学习 " href="/2020/01/26/RLTF/" data-tag="AI,数学,强化学习" data-author>
            <span class="post-title" title="RLTF">RLTF</span>
            <span class="post-date" title="2020-01-26 19:21:06">2020/01/26</span>
        </a>
        
        <a class="AI " href="/2019/09/14/deep-reinforcement-learning/" data-tag="数学,深度学习,强化学习" data-author>
            <span class="post-title" title="deep-reinforcement-learning">deep-reinforcement-learning</span>
            <span class="post-date" title="2019-09-14 10:00:12">2019/09/14</span>
        </a>
        
        <a class="编程 " href="/2019/07/23/go-http搭建服务器知识点儿/" data-tag="编程,go" data-author>
            <span class="post-title" title="go-http搭建服务器知识点儿">go-http搭建服务器知识点儿</span>
            <span class="post-date" title="2019-07-23 11:29:08">2019/07/23</span>
        </a>
        
        <a class="编程 " href="/2020/01/31/leetcode/" data-tag="数学,编程,python" data-author>
            <span class="post-title" title="leetcode">leetcode</span>
            <span class="post-date" title="2020-01-31 10:14:45">2020/01/31</span>
        </a>
        
        <a class href="/2020/06/05/lgb-note/" data-tag="AI,编程,python" data-author>
            <span class="post-title" title="lgb_note">lgb_note</span>
            <span class="post-date" title="2020-06-05 21:25:01">2020/06/05</span>
        </a>
        
        <a class="数学 " href="/2019/04/25/math/" data-tag="AI,数学,深度学习" data-author>
            <span class="post-title" title="线性代数补充笔记">线性代数补充笔记</span>
            <span class="post-date" title="2019-04-25 21:25:01">2019/04/25</span>
        </a>
        
        <a class="AI " href="/2020/06/02/pytorch-note/" data-tag="AI,python,技术小结" data-author>
            <span class="post-title" title="pytorch_note">pytorch_note</span>
            <span class="post-date" title="2020-06-02 20:19:39">2020/06/02</span>
        </a>
        
        <a class="编程 " href="/2019/04/29/使用Python实现excel中固定数据排序且改名至另一个文件夹/" data-tag="编程,python,技术小结" data-author>
            <span class="post-title" title="基于python实现excel中读取文件目录+相应数据排序+将文件重命名">基于python实现excel中读取文件目录+相应数据排序+将文件重命名</span>
            <span class="post-date" title="2019-04-29 19:30:06">2019/04/29</span>
        </a>
        
        <a class="AI " href="/2020/06/02/强化学习在滴滴网约车的应用记录/" data-tag="AI,强化学习,组会报告" data-author>
            <span class="post-title" title="强化学习在滴滴网约车的应用记录">强化学习在滴滴网约车的应用记录</span>
            <span class="post-date" title="2020-06-02 20:19:39">2020/06/02</span>
        </a>
        
        <a class="数学 " href="/2019/10/24/数值计算与凸优化补充笔记/" data-tag="AI,数学,深度学习" data-author>
            <span class="post-title" title="数值计算与凸优化补充笔记">数值计算与凸优化补充笔记</span>
            <span class="post-date" title="2019-10-24 16:14:54">2019/10/24</span>
        </a>
        
        <a class="三省吾身 " href="/2019/11/03/智源大会听报告笔记/" data-tag="三省吾身,AI" data-author>
            <span class="post-title" title="智源大会听学术报告笔记">智源大会听学术报告笔记</span>
            <span class="post-date" title="2019-11-03 13:24:12">2019/11/03</span>
        </a>
        
        <a class="编程 " href="/2019/09/05/物体检测打标小脚本-获取当前图片中鼠标位置/" data-tag="编程,python,技术小结" data-author>
            <span class="post-title" title="物体检测打标小脚本-获取当前图片中鼠标位置">物体检测打标小脚本-获取当前图片中鼠标位置</span>
            <span class="post-date" title="2019-09-05 15:30:36">2019/09/05</span>
        </a>
        
        <a class="组会报告 " href="/2019/09/26/组会报告-0930-QLearning/" data-tag="深度学习,强化学习,组会报告" data-author>
            <span class="post-title" title="组会报告-0930-QLearning">组会报告-0930-QLearning</span>
            <span class="post-date" title="2019-09-26 15:15:04">2019/09/26</span>
        </a>
        
        <a class="三省吾身 " href="/2019/04/15/考研历程反思总结/" data-tag="三省吾身,考研" data-author>
            <span class="post-title" title="考研历程反思总结">考研历程反思总结</span>
            <span class="post-date" title="2019-04-15 21:25:01">2019/04/15</span>
        </a>
        
        <a class="AI " href="/2019/07/21/计算机视觉存疑解答记录/" data-tag="AI,数学,CV" data-author>
            <span class="post-title" title="计算机视觉存疑解答记录">计算机视觉存疑解答记录</span>
            <span class="post-date" title="2019-07-21 13:04:25">2019/07/21</span>
        </a>
        
        <a class="AI " href="/2019/07/29/达观杯比赛记录/" data-tag="三省吾身,AI,NLP" data-author>
            <span class="post-title" title="达观杯比赛记录">达观杯比赛记录</span>
            <span class="post-date" title="2019-07-29 20:19:39">2019/07/29</span>
        </a>
        
    </nav>
</div>
    </div>
    <div class="hide-list">
        <div class="semicircle">
            <div class="brackets first"><</div>
            <div class="brackets">&gt;</div>
        </div>
    </div>
</aside>
<div class="post">
    <div class="pjax">
        <article id="post-组会报告-0930-QLearning" class="article article-type-post" itemscope itemprop="blogPost">
    
        <h1 class="article-title">组会报告-0930-QLearning</h1>
    
    <div class="article-meta">
        
        
        
        <span class="book">
            
                <a href="javascript:" data-rel="组会报告">组会报告</a>
            
        </span>
        
        
        <span class="tag">
            
            <a href="javascript:" class="color5">深度学习</a>
            
            <a href="javascript:" class="color5">强化学习</a>
            
            <a href="javascript:" class="color5">组会报告</a>
            
        </span>
        
    </div>
    <div class="article-meta">
        
        创建时间:<time class="date" title="更新时间: 2019-11-26 11:11:28">2019-09-26 15:15</time>
        
    </div>
    <div class="article-meta">
        
        
        <span id="busuanzi_container_page_pv">
            阅读:<span id="busuanzi_value_page_pv">
                <span class="count-comment">
                    <span class="spinner">
                      <div class="cube1"></div>
                      <div class="cube2"></div>
                    </span>
                </span>
            </span>
        </span>
        
        
        <span class="top-comment" title="跳转至评论区">
            <a href="#comments">
                评论:<span class="count-comment">
                    <span class="spinner">
                      <div class="cube1"></div>
                      <div class="cube2"></div>
                    </span>
                </span>
            </a>
        </span>
        
    </div>
    
    <div class="toc-ref">
    
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Q-learning"><span class="toc-text">Q-learning</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#铺垫知识："><span class="toc-text">铺垫知识：</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-马尔可夫决策的要求"><span class="toc-text">1.马尔可夫决策的要求</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-马尔可夫决策过程4要素以及数学符号表示"><span class="toc-text">2.马尔可夫决策过程4要素以及数学符号表示</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-on-policy与off-policy"><span class="toc-text">3.on-policy与off-policy</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-贝尔曼方程和贝尔曼最优方程"><span class="toc-text">4.贝尔曼方程和贝尔曼最优方程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-动态规划与TD，MC"><span class="toc-text">5.动态规划与TD，MC</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-动态规划"><span class="toc-text">1.动态规划</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-monte-carlo-MC"><span class="toc-text">2.monte-carlo(MC)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-Temporal-difference-TD"><span class="toc-text">3.Temporal-difference(TD)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-雏形"><span class="toc-text">1.雏形</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-改进"><span class="toc-text">2.改进</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-target-network"><span class="toc-text">1.target network</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-epsilon-greedy"><span class="toc-text">2.$\epsilon $ -greedy</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-replay-buffer"><span class="toc-text">3.replay-buffer</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-算法流程"><span class="toc-text">3.算法流程</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#需要注意的点："><span class="toc-text">需要注意的点：</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#基于模型和非基于模型"><span class="toc-text">基于模型和非基于模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#待改进："><span class="toc-text">待改进：</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Prioritized-Reply"><span class="toc-text">Prioritized Reply</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Multi-step-balance-between-MC-and-TD"><span class="toc-text">Multi-step-balance between MC and TD</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Noisy-Net"><span class="toc-text">Noisy Net</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Double-DQN"><span class="toc-text">Double DQN</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#总结："><span class="toc-text">总结：</span></a></li></ol></li></ol></li></ol></li></ol>
    
<style>
    .left-col .switch-btn,
    .left-col .switch-area {
        display: none;
    }
    .toc-level-3 i,
    .toc-level-3 ol {
        display: none !important;
    }
</style>
</div>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>组会报告-0930-QLearning</p>
<a id="more"></a>
<h1 id="Q-learning"><a href="#Q-learning" class="headerlink" title="Q-learning"></a>Q-learning</h1><h2 id="铺垫知识："><a href="#铺垫知识：" class="headerlink" title="铺垫知识："></a>铺垫知识：</h2><h3 id="1-马尔可夫决策的要求"><a href="#1-马尔可夫决策的要求" class="headerlink" title="1.马尔可夫决策的要求"></a>1.马尔可夫决策的要求</h3><p>1.能够检测到理想状态</p>
<p>2.支持多    次尝试</p>
<p>3.系统的下一个状态只与当前状态信息和当前所做动作有关，与更早之前的状态无关。</p>
<h3 id="2-马尔可夫决策过程4要素以及数学符号表示"><a href="#2-马尔可夫决策过程4要素以及数学符号表示" class="headerlink" title="2.马尔可夫决策过程4要素以及数学符号表示"></a>2.马尔可夫决策过程4要素以及数学符号表示</h3><p><strong>S状态（state）、A动作（action）、策略（policy）、R奖励（reward）</strong> 其中策略是状态到动作的映射，回报是奖励随时间步的折现或积累。^[3]^ </p>
<p>$S_t$表示t时刻的环境状态</p>
<p>$A_t$表示t时刻的动作</p>
<p>$R_t$表示t+1时刻，环境变化至$S_ {t+1} $时的奖励</p>
<p><em>π</em>(<em>a</em>|<em>s</em>)=<em>P</em>($A_t$ = <em>a</em>|<em>$S_t$</em>=<em>s</em>)最常见的策略表达方式是一个条件概率分布<em>π</em>(<em>a</em>|<em>s</em>), 即在状态<em>s</em>时采取动作<em>a</em>的概率.</p>
<p>$v^π (s)$ 是个体在策略π和状态s采取行动的<strong>累计</strong>价值</p>
<script type="math/tex; mode=display">
V^{\pi}(s)=\mathbb{E}_{\pi}\left[r_{t+1}+\gamma r_{t+2}+\gamma^{2} r_{t+3}+\cdots | s_{t}=s\right]=\mathbb{E}_{\pi}\left[\sum_{k=0}^{\infty} {\gamma^{k} r_{t+k+1}} | s_{t}=s\right]</script><p>γ是衰减因子</p>
<p>$P^a_{ss’}$ 是状态s下采取动作a，跳到状态s’的概率。</p>
<p>$\epsilon $ 是探索的概率</p>
<h3 id="3-on-policy与off-policy"><a href="#3-on-policy与off-policy" class="headerlink" title="3.on-policy与off-policy"></a>3.on-policy与off-policy</h3><p>on-policy：我们要得到的agent和跟环境互动的agent如果是同一个agent，叫on-policy(要学习的agent是一边与环境互动，一边学习的话，叫on-policy)</p>
<p>off-policy：我们要得到的agent和跟环境互动的agent如果不是同一个agent，叫off-policy（这个agent通过看别人玩儿来学习，叫off-policy）</p>
<h3 id="4-贝尔曼方程和贝尔曼最优方程"><a href="#4-贝尔曼方程和贝尔曼最优方程" class="headerlink" title="4.贝尔曼方程和贝尔曼最优方程"></a>4.贝尔曼方程和贝尔曼最优方程</h3><p>贝尔曼方程表明了当前状态的值函数与下个状态的值函数的关系。 </p>
<p>$V^{\pi}(\mathrm{s})=\sum_{s^{\prime} \in S} p\left(s^{\prime} | s, \pi(s)\right)\left[r\left(s^{\prime} | s, \pi(s)\right)+\gamma V^{π}(s)\right]=E_{\pi}\left[r\left(s^{\prime} | s, a\right)+\gamma V^{\pi}\left(s^{\prime}\right) | s_{0}=s\right]$  </p>
<p>贝尔曼最优方程：</p>
<script type="math/tex; mode=display">
V^{*}(\mathrm{s})=\max _{a} E\left[r\left(s^{\prime} | s, a\right)+\gamma V^{*}(\mathrm{s}) | s_{0}=s\right]\\ \quad \quad \quad \quad \quad \quad \quad =\max _{\alpha∈A(s)} \sum p\left(\mathrm{s}^{\prime} | s, \pi(\mathrm{s})\right)\left[\mathrm{r}\left(\mathrm{s}^{\prime} | \mathrm{s}, \pi(\mathrm{s})\right)+\gamma V^{\pi}\left(\mathrm{s}^{\prime}\right)\right]</script><p><img src="/2019/09/26/组会报告-0930-QLearning/贝尔曼方程.png" alt>     </p>
<p>这个式子告诉我们，一个状态的价值由该状态的奖励以及后续状态价值按一定的衰减比例联合组成。</p>
<p>同理推至Q-function</p>
<p>贝尔曼最优方程：</p>
<script type="math/tex; mode=display">
 \mathrm{Q}^{*}(\mathrm{s})=E\left[r\left(s^{\prime} | s, a\right)+\gamma \max _{a^{\prime}} Q^{*}\left(\mathrm{s}^{\prime}, \mathrm{a}\right) | s_{0}=s, \mathrm{a}_{0}=\mathrm{a}\right]</script><script type="math/tex; mode=display">
=\sum p\left(\mathrm{s}^{\prime} | \mathrm{s}, \pi(\mathrm{s})\right)\left[\mathrm{r}\left(\mathrm{s}^{\prime} | \mathrm{s}, \pi(\mathrm{s})\right)+\gamma \max _{(\mathrm{a}∈A(s))} Q^{*}\left(\mathrm{s}^{\prime}, \mathrm{a}\right)\right]</script><p>$Q^{\pi}(s, a)=\mathbb{E}_{\pi}\left[r_{t+1}+\gamma r_{t+2}+\gamma^{2} r_{t+3}+\cdots | s_{t}=s, a_{t}=a\right]$<br>$Q^{\pi}(s, a)=\mathbb{E}\left[r_{t+1}+\gamma \sum_{k=0}^{\infty} \gamma^{k} r_{t+k+2} | s_{t}=s, a_{t}=a\right]$<br>$Q^{\pi}(s, a)=\sum_{s^{\prime}} P_{s s^{\prime}}^{a}\left\{R_{s s^{\prime}}^{a}+\gamma \sum_{a^{\prime}} \mathbb{E}_{\pi}\left[\sum_{k=0}^{\infty} \gamma^{k} r_{t+k+2} | s_{t+1}=s^{\prime}, a_{t+1}=a^{\prime}\right]\right\}$ </p>
<script type="math/tex; mode=display">
Q^{\pi}(s, a)=\sum_{s^{\prime}} P_{s s^{\prime}}^{a}\left[R_{s s^{\prime}}^{a}+\gamma \sum_{a^{\prime}} Q^{\pi}\left(s^{\prime}, a^{\prime}\right)\right]​</script><h3 id="5-动态规划与TD，MC"><a href="#5-动态规划与TD，MC" class="headerlink" title="5.动态规划与TD，MC"></a>5.动态规划与TD，MC</h3><h4 id="1-动态规划"><a href="#1-动态规划" class="headerlink" title="1.动态规划"></a>1.动态规划</h4><p>动态规划的关键点有两个：一是问题的最优解可以由若干小问题的最优解构成，即通过寻找子问题的最优解来得到问题的最优解。第二是可以找到子问题状态之间的递推关系，通过较小的子问题状态递推出较大的子问题的状态。而强化学习的问题恰好是满足这两个条件的。^[2]^</p>
<h4 id="2-monte-carlo-MC"><a href="#2-monte-carlo-MC" class="headerlink" title="2.monte-carlo(MC)"></a>2.monte-carlo(MC)</h4><p>蒙特卡罗法通过采样若干经历完整的状态序列(episode)来估计状态的真实价值。</p>
<p>缺点，这就是它每次采样都需要一个完整的状态序列。</p>
<p><img src="/2019/09/26/组会报告-0930-QLearning/monte-carlo.png" alt></p>
<h4 id="3-Temporal-difference-TD"><a href="#3-Temporal-difference-TD" class="headerlink" title="3.Temporal-difference(TD)"></a>3.Temporal-difference(TD)</h4><p>因为第一种monte-carlo的方法需要将游戏玩到结束，所以比较耗时，在这里TD方法不需要将游戏玩到底,不需要得到总奖励值，只需要用神经网络判断出$s_t $与$s_{t+1}$的value值即可，核心公式是：$V^{\pi}\left(s_{t}\right)=V^{\pi}\left(s_{t+1}\right)+r_{t}$  </p>
<p><img src="/2019/09/26/组会报告-0930-QLearning/TD.png" alt></p>
<p>这两种方法区别与优劣：</p>
<p>1.因为游戏具有很强的随机性，所以MC这种估计总奖励值的方法所得结果的方差比较大（随机性太大，$G_a$实际上是很多state的reward之和。）</p>
<p>2.而用TD方法所得的r会比较稳定，但是缺点是$V^{\pi}\left(s_{t}\right)$和$V^{\pi}\left(s_{t+1}\right)$是当前状态价值的有偏估计，不一定很准，会导致整个式子是无效的。而蒙特卡洛算法需要知道整个序列的奖励信息，所以是当前状态价值的无偏估计。且TD更常见~</p>
<p>3.MC可以在持续的试探中学习。</p>
<p>6.Q-learning</p>
<h4 id="1-雏形"><a href="#1-雏形" class="headerlink" title="1.雏形"></a>1.雏形</h4><p> <img src="/2019/09/26/组会报告-0930-QLearning/Q-learning.png" alt> </p>
<ol>
<li>Actor-π与环境进行互动</li>
<li>使用TD或者MC的方法学到$Q^π （s,a）$ </li>
<li>找到比π<strong>好</strong>的Actor-π‘然后代替π   </li>
</ol>
<h4 id="2-改进"><a href="#2-改进" class="headerlink" title="2.改进"></a>2.改进</h4><h5 id="1-target-network"><a href="#1-target-network" class="headerlink" title="1.target network"></a>1.target network</h5><p>在训练$Q^π （s,a）$ 模型的时候，因为输出值和目标值都是在变化的，所以训练过程很不稳定，故将$s_{t+1} $的$Q^π$ 固定住，只更新$s_{t} $的$Q^π$  ，使$r_t$ 达到最大而用梯度上升法更新参数，更新小数量次数后，再用更新过的参数替换掉之前固定的$Q^π$ </p>
<p><img src="/2019/09/26/组会报告-0930-QLearning/targetnetwork.png" alt></p>
<h5 id="2-epsilon-greedy"><a href="#2-epsilon-greedy" class="headerlink" title="2.$\epsilon $ -greedy"></a>2.$\epsilon $ -greedy</h5><p>因为之前是强制让action为能获得最大奖励的动作，这个是存在一定问题的：就是一旦有个策略之前没有被发掘出来（没有被example到的话），那么就永远定格了。</p>
<p>——————————————-小分割线—————————————↓</p>
<p>这个问题就像去餐厅点餐一样，如果第一次吃麻辣香锅还行，那么如果按照之前的算法来搞的话，就是每次都去点麻辣香锅，这是不科学的。</p>
<p>——————————————-小分割线—————————————↑</p>
<p>解决办法1：</p>
<p>epsilon greedy ($\epsilon$ 随着时间减少)</p>
<p>$a=\left\{\begin{array}{cc}{\arg \max \limits_{a} Q(s, a),} &amp; {\text { with probability } 1-\varepsilon} \ {\text { random, }} &amp; {\text { otherwise }}\end{array}\right.$</p>
<p>解决办法2：</p>
<p>根据Q值设定几率：</p>
<p>$P(a | s)=\frac{\exp (Q(s, a))}{\sum_{a} \exp (Q(s, a))}$ </p>
<h5 id="3-replay-buffer"><a href="#3-replay-buffer" class="headerlink" title="3.replay-buffer"></a>3.replay-buffer</h5><p>1.把之前不同情况下π与环境做互动所收集到的data都放到一个buffer里面，使数据多样化，有利于训练。</p>
<p>2.将π’得到的新data替换掉之前的旧data，更新数据。</p>
<p>3.buffer里面不是trajectory，而是一些experience，所以即使里面是别的经验也都OK。 </p>
<h4 id="3-算法流程"><a href="#3-算法流程" class="headerlink" title="3.算法流程"></a>3.算法流程</h4><p><img src="/2019/09/26/组会报告-0930-QLearning/算法流程.png" alt> </p>
<h3 id="需要注意的点："><a href="#需要注意的点：" class="headerlink" title="需要注意的点："></a>需要注意的点：</h3><h4 id="基于模型和非基于模型"><a href="#基于模型和非基于模型" class="headerlink" title="基于模型和非基于模型"></a>基于模型和非基于模型</h4><p>基于模型 (Model-based) 和非基于模型 (Model-free)。基于模型的强化学习算法是知道并可以存储所有马尔科夫决策过程信息，非基于模型的强化学习算法则需要自己探索未知的马尔科夫过程。</p>
<h4 id="待改进："><a href="#待改进：" class="headerlink" title="待改进："></a>待改进：</h4><h5 id="Prioritized-Reply"><a href="#Prioritized-Reply" class="headerlink" title="Prioritized Reply"></a>Prioritized Reply</h5><p>好的数据经验应该有更大的几率被选到。</p>
<h5 id="Multi-step-balance-between-MC-and-TD"><a href="#Multi-step-balance-between-MC-and-TD" class="headerlink" title="Multi-step-balance between MC and TD"></a>Multi-step-balance between MC and TD</h5><p>在experience buffer里面存储N个step</p>
<p>$\left(s_{t}, a_{t}, r_{t}, \cdots, s_{t+N}, a_{t+N}, r_{t+N}, s_{t+N+1}\right)$</p>
<p>因此式子改为：$Q\left(s_{t}, a_{t}\right)&lt;-&gt;\sum_{t^{\prime}=t}^{t+N} r_{t^{\prime}}+\hat{Q}\left(s_{t+N+1}, a_{t+N+1}\right)$ </p>
<h5 id="Noisy-Net"><a href="#Noisy-Net" class="headerlink" title="Noisy Net"></a>Noisy Net</h5><p>原来是用epsilon-greedy的方法</p>
<p>但是这个方法存在个问题：给同样的state，智能体所采取的动作不一定相同，具有很强的随机性，这是不合适的。举个例子就是：我去食堂打饭，如果每次遇到的场景相同，我应该选择相同的菜(麻辣香锅)，而不是之前说的epsilon-greedy方法还会有一定的概率会选别的菜，在这里的一定概率就体现为随机乱试。而如果我的Q进行微调(加入今天中午就想吃点儿酸甜的，那我不会选麻辣香锅，而是选择糖醋里脊，这是因为我的某一个控制酸甜的参数增高了，这是非常系统的尝试。)</p>
<p>因此现在将Q的参数加上高斯噪音，变为$\tilde{Q}(s, a)$  直到本场游戏玩到结束，再对参数更改。</p>
<h5 id="Double-DQN"><a href="#Double-DQN" class="headerlink" title="Double DQN"></a>Double DQN</h5><p>之前单独的DQN存在的问题：</p>
<p>Q-function对实际情况的判断会有虚高：</p>
<p>$Q\left(s_{t}, a_{t}\right)  &lt;-&gt; r_{t}+\max \limits_{a} Q\left(s_{t+1}, a\right)$</p>
<p>因为target值中有一项是$\max\limits_{a} Q\left(s_{t+1}, a\right)$ 很容易会被设的特别高，但是真正的$Q\left(s_{t+1}, a\right)$ 可能没有那么高，所以导致$Q\left(s_{t}, a_{t}\right) $虚高。</p>
<p>而Double-DQN的做法是用两个Q-function，即选Action的Q-function和算Q-value的Q-function不是同一个。</p>
<p>$Q\left(s_{t}, a_{t}\right) &lt;-&gt; r_{t}+Q^{\prime}\left(s_{t+1}, \arg \max \limits_{a} Q\left(s_{t+1}, a\right)\right)$  </p>
<p>其中Q’是没更新之前，Q是正在更新的Q-function。</p>
<p>——————————————-小分割线—————————————↓</p>
<p>通俗理解就是：我现在正在上研究生，$Q\left(s_{t+1}, a\right)$ 为我选择工作的公司所带给我的价值，以目前的视野所见，最厉害的可能是去google即Q(选公司，去谷歌)=100，其实实际上Q(选公司，去谷歌)的真实值没有那么高，也就90，但以我目前的价值观会认为他贼高，这样就直接把双箭头右侧的的值判断过高，间接的使得当前的$Q\left(s_{t}, a_{t}\right)$也判断虚高。</p>
<p>而Double-DQN的深层一点可理解的含义是2个不同的价值观，其中Q’是参数未更新的价值判断函数，Q是正在准备更新的价值判断函数，也就是说Q’是我大学本科时候的价值观，Q是我现在的价值观，即使$\arg \max \limits_{a} Q\left(s_{t+1}, a\right)$ 所判断的动作是虚高的去谷歌，但是在本科时候的价值观体系里去华为和思科这种网络巨头的价值才是最大的，所以Q’（本科找工作，去谷歌）的值会相应的减小，这样就达到了防止Q-function判断价值虚高情况。</p>
<p>——————————————-小分割线—————————————↑</p>
<h4 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h4><p>Qlearning的<strong>主要优势</strong>就是使用了<strong>时间差分法TD</strong>（融合了蒙特卡洛和动态规划）能够进行<strong>离线学习</strong>, 使用<strong>bellman方程</strong>可以对<strong>马尔科夫过程</strong>求解最优策略。^[1]^</p>
<p>[1] <a href="https://blog.csdn.net/qq_30615903/article/details/80739243" target="_blank" rel="noopener">https://blog.csdn.net/qq_30615903/article/details/80739243</a></p>
<p>[2] <a href="https://www.cnblogs.com/pinard/p/9463815.html" target="_blank" rel="noopener">https://www.cnblogs.com/pinard/p/9463815.html</a></p>
<p>[3]<a href="https://baike.baidu.com/item/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%93%BE/6171383?fr=aladdin" target="_blank" rel="noopener">https://baike.baidu.com/item/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%93%BE/6171383?fr=aladdin</a></p>

      
       <hr><span style="font-style: italic;color: gray;"> 转载请注明来源，欢迎对文章中的引用来源进行考证，欢迎指出任何有错误或不够清晰的表达。可以在下面评论区评论，也可以邮件至 1415500736@qq.com </span>
    </div>
</article>


<p>
    <a href="javascript:void(0)" class="dashang" onclick="dashangToggle()">赏</a>
</p>


<div class="article_copyright">
    <p><span class="copy-title">文章标题:</span>组会报告-0930-QLearning</p>
    
    <p><span class="copy-title">本文作者:</span><a href="javascript:void(0)" title="Rock">Rock</a></p>
    <p><span class="copy-title">发布时间:</span>2019-09-26, 15:15:04</p>
    <p><span class="copy-title">最后更新:</span>2019-11-26, 11:11:28</p>
    <span class="copy-title">原始链接:</span><a class="post-url" href="/2019/09/26/组会报告-0930-QLearning/" title="组会报告-0930-QLearning">http://rock-blog.top/2019/09/26/组会报告-0930-QLearning/</a>
    <p>
        <span class="copy-title">版权声明:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" title="CC BY-NC-SA 4.0 International" target="_blank">"署名-非商用-相同方式共享 4.0"</a> 转载请保留原文链接及作者。
    </p>
</div>



    <div id="comments"></div>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">

<script type="text/javascript">
    $.getScript('/js/gitalk.js', function () {
        var gitalk = new Gitalk({
            clientID: 'ff543555c057397a2a97',
            clientSecret: 'b307c20f57abf09094a4ff85a4b95f98ed9f6b61',
            repo: 'guobaoyo.github.io',
            owner: 'guobaoyo',
            admin: ['guobaoyo'],
            id: decodeURI(location.pathname),
            distractionFreeMode: 'true',
            language: 'zh-CN',
            perPage: parseInt('10',10)
        })
        gitalk.render('comments')
    })
</script>




    
        <!-- MathJax配置，可通过单美元符号书写行内公式等 -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
        preferredFont: "TeX",
        availableFonts: ["STIX","TeX"],
        linebreaks: { automatic:true },
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
        Macros: { href: "{}" }
    },
    messageStyle: "none"
    });
</script>
<!-- 给MathJax元素添加has-jax class -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<!-- 通过连接CDN加载MathJax的js代码 -->
<script type="text/javascript" async src="//cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<input type="hidden" id="MathJax-js" value="//cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">

    




    </div>
    <div class="copyright">
        <p class="footer-entry">©2016-2019 Rock&#39;s  blog</p>
<p class="footer-entry">Built with <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/yelog/hexo-theme-3-hexo" target="_blank">3-hexo</a> theme</p>

    </div>
    <div class="full-toc">
        <button class="full"><span class="min "></span></button>
<button class="post-toc-menu"><span class="post-toc-menu-icons"></span></button>
<div class="post-toc"><span class="post-toc-title">目录</span>
    <div class="post-toc-content">

    </div>
</div>
<a class id="rocket" href="javascript:void(0)"></a>
    </div>
</div>
<div class="acParent"></div>

<div class="hide_box" onclick="dashangToggle()"></div>
<div class="shang_box">
    <a class="shang_close" href="javascript:void(0)" onclick="dashangToggle()">×</a>
    <div class="shang_tit">
        <p>喜欢就点赞,疼爱就打赏</p>
    </div>
    <div class="shang_payimg">
        <div class="pay_img">
            <img src="/img/alipay.jpg" class="alipay" title="扫码支持">
            <img src="/img/weixin.jpg" class="weixin" title="扫码支持">
        </div>
    </div>
    <div class="shang_payselect">
        <span><label><input type="radio" name="pay" checked value="alipay">支付宝</label></span><span><label><input type="radio" name="pay" value="weixin">微信</label></span>
    </div>
</div>


</body>
<script src="/js/jquery.pjax.js?v=1.0.1"></script>

<script src="/js/script.js?v=1.0.1"></script>
<script>
    var img_resize = 'default';
    /*作者、标签的自动补全*/
    $(function () {
        $('.search').AutoComplete({
            'data': ['#三省吾身','#AI','#数学','#编程','#深度学习','#CV','#python','#强化学习','#go','#技术小结','#组会报告','#考研','#NLP',],
            'itemHeight': 20,
            'width': 418
        }).AutoComplete('show');
    })
    function initArticle() {
        /*渲染对应的表格样式*/
        
            $(".post .pjax table").addClass("green_title");
        

        /*渲染打赏样式*/
        
        $("input[name=pay]").on("click", function () {
            if($("input[name=pay]:checked").val()=="weixin"){
                $(".shang_box .shang_payimg .pay_img").addClass("weixin_img");
            } else {
                $(".shang_box .shang_payimg .pay_img").removeClass("weixin_img");
            }
        })
        

        /*高亮代码块行号*/
        
        $('pre code').each(function(){
            var lines = $(this).text().split('\n').length - 1, widther='';
            if (lines>99) {
                widther = 'widther'
            }
            var $numbering = $('<ul/>').addClass('pre-numbering ' + widther).attr("unselectable","on");
            $(this).addClass('has-numbering ' + widther)
                    .parent()
                    .append($numbering);
            for(var i=1;i<=lines;i++){
                $numbering.append($('<li/>').text(i));
            }
        });
        

        /*访问数量*/
        
        $.getScript("//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js");
        

        /*代码高亮，行号对齐*/
        $('.pre-numbering').css('line-height',$('.has-numbering').css('line-height'));

        
    }

    /*打赏页面隐藏与展示*/
    
    function dashangToggle() {
        $(".shang_box").fadeToggle();
        $(".hide_box").fadeToggle();
    }
    

</script>

<!--加入行号的高亮代码块样式-->

<style>
    pre{
        position: relative;
        margin-bottom: 24px;
        border-radius: 10px;
        border: 1px solid #e2dede;
        background: #FFF;
        overflow: hidden;
    }
    code.has-numbering{
        margin-left: 30px;
    }
    code.has-numbering.widther{
        margin-left: 35px;
    }
    .pre-numbering{
        margin: 0px;
        position: absolute;
        top: 0;
        left: 0;
        width: 20px;
        padding: 0.5em 3px 0.7em 5px;
        border-right: 1px solid #C3CCD0;
        text-align: right;
        color: #AAA;
        background-color: #fafafa;
    }
    .pre-numbering.widther {
        width: 35px;
    }
</style>

<!--自定义样式设置-->
<style>
    
    
    .nav {
        width: 542px;
    }
    .nav.fullscreen {
        margin-left: -542px;
    }
    .nav-left {
        width: 120px;
    }
    
    
    @media screen and (max-width: 1468px) {
        .nav {
            width: 492px;
        }
        .nav.fullscreen {
            margin-left: -492px;
        }
        .nav-left {
            width: 100px;
        }
    }
    
    
    @media screen and (max-width: 1024px) {
        .nav {
            width: 492px;
            margin-left: -492px
        }
        .nav.fullscreen {
            margin-left: 0;
        }
        .nav .hide-list.fullscreen {
            left: 492px
        }
    }
    
    @media screen and (max-width: 426px) {
        .nav {
            width: 100%;
        }
        .nav-left {
            width: 100%;
        }
    }
    
    
    .nav-right .title-list nav a .post-title, .nav-right .title-list #local-search-result a .post-title {
        color: #383636;
    }
    
    
    .nav-right .title-list nav a .post-date, .nav-right .title-list #local-search-result a .post-date {
        color: #5e5e5f;
    }
    
    
    .nav-right nav a.hover, #local-search-result a.hover{
        background-color: #c1bfc1;
    }
    
    

    /*列表样式*/
    
    .post .pjax article .article-entry>ol, .post .pjax article .article-entry>ul, .post .pjax article>ol, .post .pjax article>ul{
        border: #e2dede solid 1px;
        border-radius: 10px;
        padding: 10px 32px 10px 56px;
    }
    .post .pjax article .article-entry li>ol, .post .pjax article .article-entry li>ul,.post .pjax article li>ol, .post .pjax article li>ul{
        padding-top: 5px;
        padding-bottom: 5px;
    }
    .post .pjax article .article-entry>ol>li, .post .pjax article .article-entry>ul>li,.post .pjax article>ol>li, .post .pjax article>ul>li{
        margin-bottom: auto;
        margin-left: auto;
    }
    .post .pjax article .article-entry li>ol>li, .post .pjax article .article-entry li>ul>li,.post .pjax article li>ol>li, .post .pjax article li>ul>li{
        margin-bottom: auto;
        margin-left: auto;
    }
    

    /* 背景图样式 */
    
    


    /*引用块样式*/
    

    /*文章列表背景图*/
    
    .nav-right:before {
        content: ' ';
        display: block;
        position: absolute;
        left: 0;
        top: 0;
        width: 100%;
        height: 100%;
        opacity: 0.5;
        background: url("https://i.loli.net/2019/07/22/5d3521411f3f169375.png");
        background-repeat: no-repeat;
        background-position: 50% 0;
        -ms-background-size: cover;
        -o-background-size: cover;
        -moz-background-size: cover;
        -webkit-background-size: cover;
        background-size: cover;
    }
    

    
</style>







</html>
