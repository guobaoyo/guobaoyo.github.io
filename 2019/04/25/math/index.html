<!DOCTYPE html>
<html>
  <!-- Html Head Tag-->
  <head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content>
  <meta name="author" content="Rock">
  <!-- Open Graph Data -->
  <meta property="og:title" content="深度学习相关数学知识">
  <meta property="og:description" content>
  <meta property="og:site_name" content="Rock-Blog">
  <meta property="og:type" content="article">
  <meta property="og:image" content="http://rock-blog.top">
  
    <link rel="alternate" href="/atom.xml" title="Rock-Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  

  <!-- Site Title -->
  <title>Rock-Blog</title>

  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="/css/bootstrap.min.css">
  <!-- Custom CSS -->
  
  <link rel="stylesheet" href="/css/style.light.css">

  <!-- Google Analytics -->
  

</head>

  <body>
    <!-- Page Header -->


<header class="site-header header-background" style="background-image: url(/img/龙珠3.jpg)">
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <div class="page-title with-background-image">
          <p class="title">深度学习相关数学知识</p>
          <p class="subtitle"></p>
        </div>
        <div class="site-menu with-background-image">
          <ul>
            
              <li>
                <a href="/">
                  
                  Home
                  
                </a>
              </li>
            
              <li>
                <a href="/archives">
                  
                  Archives
                  
                </a>
              </li>
            
              <li>
                <a href="https://github.com/guobaoyo">
                  
                  Github
                  
                </a>
              </li>
            
              <li>
                <a href="mailto:shi_chenggong@163.com">
                  
                  Email
                  
                </a>
              </li>
            
          </ul>
        </div>
      </div>
    </div>
  </div>
</header>

<article>
  <div class="container typo">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <div class="post-info text-muted">
          
            <!-- Author -->
            <span class="author info">By Rock</span>
          
          <!-- Date -->
          <span class="date-time info">On
            <span class="date">2019-04-25</span>
            <span class="time">14:27:07</span>
          </span>
          
          <!--  Categories  -->
            <span class="categories info">Under 

<a href="/categories/深度学习/">深度学习</a>
</span>
          
        </div>
        <!-- Tags -->
        
          <div class="post-tags text-muted">
            Tags: 

<a class="tag" href="/tags/深度学习/">#深度学习</a> <a class="tag" href="/tags/人工智能/">#人工智能</a> <a class="tag" href="/tags/数学/">#数学</a>


          </div>
        
        <!-- Post Main Content -->
        <div class="post-content">
          <p>本笔记是对深度学习相关知识的数学补充笔记—出自<strong>Linear Algebra Review and Reference-Zico Kolter</strong></p>
<p>背景状态：刚考完研对部分数学知识模糊</p>
<a id="more"></a>
<h1 id="线性代数"><a href="#线性代数" class="headerlink" title="线性代数"></a>线性代数</h1><h2 id="1-补充基本概念"><a href="#1-补充基本概念" class="headerlink" title="1.补充基本概念"></a>1.补充基本概念</h2><p><strong>奇异矩阵</strong> ：一个列向量线性相关的方阵称为奇异矩阵。</p>
<p><strong>二次型矩阵</strong>：对于$A∈\mathbb R^{n×n}$ 和一个向量$x∈\mathbb R^n$ $x^TAx$形式称为二次型，记为：</p>
<p>$x^{T} A x=\sum_{i=1}^{n} x_{i}(A x)_{i}=\sum_{i=1}^{n} x_{i}\left(\sum_{j=1}^{n} A_{i j} x_{j}\right)=\sum_{i=1}^{n} \sum_{j=1}^{n} A_{i j} x_{i} x_{j}$  </p>
<p><strong>正定矩阵</strong>：设A是n阶方阵，如果对任何非零向量x，都有$x^T Mx&gt;0$，其中$ x^T$表示$x$的转置，就称A为正定矩阵。记为$A&gt;0$且正定矩阵的所有特征值都大于0</p>
<p><strong>半正定矩阵</strong>：设A是n阶方阵，如果对任何非零向量X，都有$x^T A x ≥0$，就称A为半正定矩阵。记为$A≥0$ </p>
<p>且半正定矩阵的所有特征值均不小于0</p>
<p><strong>负定矩阵</strong>：设A是n阶方阵，如果对任何非零向量x，都有$x^T Mx&lt;0$，其中$ x^T$表示$x$的转置，就称A为正定矩阵。记为$A&lt;0$</p>
<p><strong>半负定矩阵</strong>：设A是n阶方阵，如果对任何非零向量X，都有$x^T A x ≤0$，就称A为半正定矩阵。记为$A≤0$ </p>
<p><strong>性质补充</strong>：</p>
<ul>
<li>正定或者负定矩阵必须是满秩矩阵</li>
<li>矩阵$A∈\mathbb R^{m×n}$ ，既不用要求矩阵A是对称矩阵也不用要求矩阵A是方阵，gram矩阵$G=A^TA$总是半正定的，更进一步若m≥n，G是正定矩阵。 </li>
</ul>
<p>注：</p>
<p>​    1.一般情况下说矩阵的逆，矩阵都是方阵，且所有列向量都是线性无关的。</p>
<p>​    2.由于奇异矩阵或非方阵的矩阵不存在逆矩阵，则求其逆为该矩阵的伪逆矩阵X，X是一个与A的转置矩阵A’ 同型    的矩阵，并且满足：AXA=A,XAX=X.    此时，称矩阵X为矩阵A的伪逆，也称为广义逆矩阵。</p>
<p>​    3.矩阵$A∈ \mathbb R^{m×n}$ 可写为以下两种形式，在后续部分数学推导中会用到：</p>
<p>​        $A=\left[\begin{array}{llll}{|} &amp; {|} &amp; {|} &amp;{|}\ {a_{1}} &amp; {a_{2}} &amp; {\cdots} &amp; {a_{n}} \ {|} &amp; {|} &amp; {|} &amp; {|}\end{array}\right]$   或者$A=\left[\begin{array}{c}{-a_{1}^{T}-} \ {-a_{2}^{T}-} \ {\vdots} \ {-a_{m}^{T}-}\end{array}\right]$ <strong>注意这里的$a_1$与$a_1^T$并不是同一个向量</strong>  </p>
<h2 id="2-矩阵乘法"><a href="#2-矩阵乘法" class="headerlink" title="2.矩阵乘法"></a>2.矩阵乘法</h2><p>$x,y∈R^n$ 则$x^T y$被称为<strong>点积</strong>(dot product )也称为<strong>内积</strong>（inner product）</p>
<script type="math/tex; mode=display">
x^{T} y \in \mathbb{R}=\left[\begin{array}{llll}{x_{1}} & {x_{2}} & {\cdots} & {x_{n}}\end{array}\right]\left[\begin{array}{c}{y_{1}} \\ {x_{2}} \\ {\vdots} \\ {y_{n}}\end{array}\right]=\sum_{i=1}^{n} x_{i} y_{i}</script><p>$x∈\mathbb R^m,y∈\mathbb R^n$ 则$x y^T∈\mathbb R^{m×n}$被称为<strong>外积</strong>(outer product )</p>
<script type="math/tex; mode=display">
x y^{T} \in \mathbb{R}^{m \times n}=\left[\begin{array}{c}{x_{1}} \\ {x_{2}} \\ {\vdots} \\ {x_{m}}\end{array}\right]\left[\begin{array}{llll}{y_{1}} & {y_{2}} & {\cdots} & {y_{n}}\end{array}\right]=\left[\begin{array}{cccc}{x_{1} y_{1}} & {x_{1} y_{2}} & {\cdots} & {x_{1} y_{n}} \\ {x_{2} y_{1}} & {x_{2} y_{2}} & {\cdots} & {x_{2} y_{n}} \\ {\vdots} & {\vdots} & {\ddots} & {\vdots} \\ {x_{m} y_{1}} & {x_{m} y_{2}} & {\cdots} & {x_{m} y_{n}}\end{array}\right]</script><h3 id="矩阵与向量相乘"><a href="#矩阵与向量相乘" class="headerlink" title="矩阵与向量相乘"></a>矩阵与向量相乘</h3><p>矩阵$A∈\mathbb R^{m×n}$  向量$x∈\mathbb R^n$ 则$y=Ax∈\mathbb R^m$ 由第一部分中注3可将矩阵A写为</p>
<p><strong>第一种形式</strong>：</p>
<script type="math/tex; mode=display">
y=A x=\left[\begin{array}{c}{-a_{1}^{T}-} \\ {-a_{2}^{T}-} \\ {\vdots} \\ {-a_{m}^{T}-}\end{array}\right] x=\left[\begin{array}{c}{a_{1}^{T} x} \\ {a_{2}^{T} x} \\ {\vdots} \\ {a_{m}^{T} x}\end{array}\right]</script><p>上式中第$i$个$y$是A的第$i$行与$x$的内积即$y_i=a_i^Tx$   </p>
<p><strong>第二种形式</strong>：</p>
<script type="math/tex; mode=display">
y=A x=\left[\begin{array}{cccc}{|} & {|} & {|} & {|} \\ {a_{1}} & {a_{2}} & {\cdots} & {a_{n}} \\ {|} & {|} & {|} & {|}\end{array}\right]\left[\begin{array}{c}{x_{1}} \\ {x_{2}} \\ {\vdots} \\ {x_{n}}\end{array}\right]=\left[\begin{array}{c}\\{a_{1}} \\ {}\end{array}\right] x_{1}+\left[\begin{array}{c}\\{a_{2}} \\ {}\end{array}\right] x_{2}+\ldots+\left[\begin{array}{c}\\{a_{n}} \\ {}\end{array}\right] x_{n}</script><p>第二种形式中$y$是A列向量的线性组合，且线性组合的系数是为$x$ 。</p>
<p>上面两种形式均为在矩阵$A$的右侧乘以一个列向量，同理也可以在矩阵$A$的左侧乘以一个行向量，写为$y^T=x^TA$</p>
<p>且$A∈\mathbb R ^{m×n}， x∈\mathbb R^m  ,y∈\mathbb R^n$    同理可以将$y^T$ 写为两种形式：</p>
<p><strong>第一种形式</strong>：</p>
<script type="math/tex; mode=display">
y^{T}=x^{T} A=x^{T}\left[\begin{array}{cccc}{|} & {|} & {|} & {|} \\ {a_{1}} & {a_{2}} & {\cdots} & {a_{n}} \\ {|} & {|} & {|} & {|}\end{array}\right]=\left[\begin{array}{llll}{x^{T} a_{1}} & {x^{T} a_{2}} & {\cdots} & {x^{T} a_{n}}\end{array}\right]</script><p><strong>第二种形式</strong>： </p>
<script type="math/tex; mode=display">
\begin{aligned} y^{T} &=x^{T} A \\ &=\left[\begin{array}{llll}{x_{1}} & {x_{2}} & {\cdots} & {x_{n}}\end{array}\right]\left[\begin{array} {c} {-a_{1}^{T}-} \\ {-}{a_{2}^{T}-} \\ {\vdots} {} \\ {-} {a_{m}^{T}-}\end{array}\right] \\ &=x_{1}\left[\begin{array}{cc}{-a_{1}^{T}} {-}\end{array}\right]+x_{2}\left[\begin{array}{cc}{-a_{2}^{T}} {-}\end{array}\right]+\ldots+x_{n}\left[-a_{n}^{T}-\right] \end{aligned}</script><h3 id="矩阵与矩阵相乘"><a href="#矩阵与矩阵相乘" class="headerlink" title="矩阵与矩阵相乘"></a>矩阵与矩阵相乘</h3><p>与之前类似，我们可以将$C=AB$写为4种形式(其中$A∈\mathbb R^{m×n} ,B∈\mathbb R^{n×p},C∈\mathbb R^{m×p} $ )： </p>
<p><strong>第一种形式</strong>：</p>
<script type="math/tex; mode=display">
C=A B=\left[\begin{array}{c}{-a_{1}^{T}-} \\ {-a_{2}^{T}-} \\ {\vdots} \\ {-a_{m}^{T}-}\end{array}\right]\left[\begin{array}{cccc}{|} & {|} & {} & {|} \\ {b_{1}} & {b_{2}} & {\cdots} & {b_{p}} \\ {|} & {|} & {} & {|}\end{array}\right]=\left[\begin{array}{cccc}{a_{1}^{T} b_{1}} & {a_{1}^{T} b_{2}} & {\cdots} & {a_{1}^{T} b_{p}} \\ {a_{2}^{T} b_{1}} & {a_{2}^{T} b_{2}} & {\cdots} & {a_{2}^{T} b_{p}} \\ {\vdots} & {\vdots} & {\ddots} & {\vdots} \\ {a_{m}^{T} b_{1}} & {a_{m}^{T} b_{2}} & {\cdots} & {a_{m}^{T} b_{p}}\end{array}\right]</script><p><strong>第二种形式</strong>：</p>
<script type="math/tex; mode=display">
C=A B=\left[\begin{array}{cccc}{|} & {|} & {} & {|} \\ {a_{1}} & {a_{2}} & {\cdots} & {a_{n}} \\ {|} & {|} & {} & {|}\end{array}\right]\left[\begin{array}{c}{-b_{1}^{T}-} \\ {-b_{2}^{T}-} \\ {\vdots} \\ {-b_{n}^{T}-}\end{array}\right]=\sum_{i=1}^{n} a_{i} b_{i}^{T}</script><p><strong>第三种形式</strong>：</p>
<script type="math/tex; mode=display">
C=A B=A\left[\begin{array}{cccc}{|} & {|} & {} & {|} \\ {b_{1}} & {b_{2}} & {\cdots} & {b_{p}} \\ {|} & {|} & {} & {|}\end{array}\right]=\left[\begin{array}{ccc}{|} & {|} & {} & {|}\\ {A b_{1}} & {A b_{2}} & {\cdots} & {A b_{p}} \\ {|} & {|} & {} & {|}\end{array}\right]</script><p><strong>第四种形式</strong>：</p>
<script type="math/tex; mode=display">
C=A B=\left[\begin{array}{c}{-a_{1}^{T}-} \\ {-a_{2}^{T}-} \\ {\vdots} \\ {-a_{m}^{T}-}\end{array}\right] B=\left[\begin{array}{c}{-a_{1}^{T} B-} \\ {-a_{2}^{T} B-} \\ {\vdots} \\ {-a_{m}^{T} B-}\end{array}\right]</script><h3 id="证明矩阵乘法结合律"><a href="#证明矩阵乘法结合律" class="headerlink" title="证明矩阵乘法结合律"></a><strong>证明矩阵乘法结合律</strong></h3><script type="math/tex; mode=display">
\begin{aligned}((A B) C)_{i j} &=\sum_{k=1}^{p}(A B)_{i k} C_{k j}=\sum_{k=1}^{p}\left(\sum_{l=1}^{n} A_{i l} B_{l k}\right) C_{k j} \\ &=\sum_{k=1}^{p}\left(\sum_{l=1}^{n} A_{i l} B_{l k} C_{k j}\right)=\sum_{l=1}^{n}\left(\sum_{k=1}^{p} A_{i l} B_{l k} C_{k j}\right) \\ &=\sum_{l=1}^{n} A_{i l}\left(\sum_{k=p}^{n} B_{l k} C_{k j}\right)=\sum_{l=1}^{n} A_{i l}(B C)_{l j}=(A(B C))_{i j} \end{aligned}</script><h3 id="矩阵的性质补充"><a href="#矩阵的性质补充" class="headerlink" title="矩阵的性质补充"></a>矩阵的性质补充</h3><p>1.$(A^T)^T=A$ </p>
<p>2.$(A+B)^T=A^T+B^T$ </p>
<p>3.反对称矩阵：$A=-A^T$  且易得对于一个方阵$A∈\mathbb R^{n×n}$ $A+A^T$是对称阵，$A-A^T$是反对称阵</p>
<p>4.矩阵的迹性质补充：</p>
<p>​    4.1：$A,B∈\mathbb R^{n×n} \quad tr(A+B)=trA+trB$   </p>
<p>​    4.2：$A∈\mathbb R^{n×n} \quad t∈\mathbb R \quad tr(tA)=t*trA$ </p>
<p>​    4.3在$A∈\mathbb R^{m×n},B∈\mathbb R^{n×m}$证明$trAB=trBA$ </p>
<script type="math/tex; mode=display">
\begin{aligned} \operatorname{tr} A B &=\sum_{i=1}^{m}(A B)_{i i}=\sum_{i=1}^{m}\left(\sum_{j=1}^{n} A_{i j} B_{j i}\right) \\ &=\sum_{i=1}^{m} \sum_{j=1}^{n} A_{i j} B_{j i}=\sum_{j=1}^{n} \sum_{i=1}^{m} B_{j i} A_{i j} \\ &=\sum_{j=1}^{n}\left(\sum_{i=1}^{m} B_{j i} A_{i j}\right)=\sum_{j=1}^{n}(B A)_{j j}=\operatorname{tr} B A \end{aligned}</script><p>5.矩阵的秩：</p>
<p>​    5.1三秩相等：矩阵A的行秩等于A的列秩等于A的秩</p>
<p>​    5.2对于$A∈\mathbb R^{m×n}，rank(A)=rank(A^T)$ </p>
<p>​    5.3$A∈\mathbb R^{m×n}，rank(A)≤min(m,n)$且如果 $rank(A)=min(m,n)$ 称A为满秩</p>
<p>​    5.4$A∈\mathbb R^{m×n}，B∈\mathbb R^{n×p}，rank(AB)≤min(rank(A)，rank(B))$ </p>
<p>​    5.5$A,B∈\mathbb R^{m×n}，rank(A+B)≤rank(A)+rank(B)$  </p>
<p>6.矩阵的逆：</p>
<p>​    6.1$(A^{-1})^{-1} =A$</p>
<p>​    6.2$(AB)^{-1}=B^{-1}A^{-1}$</p>
<p>​    6.3$(A^{-1})^T=(A^T)^{-1}$ </p>
<p>7.正交矩阵：</p>
<p>​    7.1正交矩阵的逆等于正交矩阵的转秩</p>
<p>​    7.2一个向量与一个正交阵相乘所得的$L^2$ 范数与该向量的$L^2$范数相等：</p>
<p>​        $||Ux||_2 = ||x||_2$ </p>
<h2 id="3-矩阵的列空间，零空间知识补充-【1】"><a href="#3-矩阵的列空间，零空间知识补充-【1】" class="headerlink" title="3.矩阵的列空间，零空间知识补充^【1】^"></a>3.矩阵的列空间，零空间知识补充^【1】^</h2><h3 id="列空间"><a href="#列空间" class="headerlink" title="列空间"></a>列空间</h3><p>m × n矩阵$A$,n×1矩阵$x$,m×1的矩阵b，运算$Ax=b$：</p>
<script type="math/tex; mode=display">
\left[\begin{array}{ccccc}{a_{11}} & {a_{12}} & {\cdots} & {a_{1(n-1)}} & {a_{1 n}} \\ {a_{21}} & {a_{22}} & {\cdots} & {a_{2(n-1)}} & {a_{2 n}} \\ {\vdots} & {\vdots} & {\ddots} & {\vdots} & {\vdots} \\ {a_{m 1}} & {a_{m 2}} & {\cdots} & {a_{m(n-1)}} & {a_{m n}}\end{array}\right] \cdot\left[\begin{array}{c}{x_{1}} \\ {x_{2}} \\ {\vdots} \\ {x_{n-1}} \\ {x_{n}}\end{array}\right]=\left[\begin{array}{c}{b_{1}} \\ {b_{2}} \\ {\vdots} \\ {b_{m}}\end{array}\right]</script><p>将$A$中的每一列看为一个向量，$A=(v_1  v_2  v_3…  v_n   )$,由A的列向量生成的子空间为A的列空间。记为</p>
<script type="math/tex; mode=display">
\mathcal{R}(A)=\left\{v \in \mathbb{R}^{m}: v=A x, x \in \mathbb{R}^{n}\right\}</script><h3 id="零空间"><a href="#零空间" class="headerlink" title="零空间"></a>零空间</h3><p>矩阵A的零空间是$Av=0$的所有解$v$的集合。记为：</p>
<script type="math/tex; mode=display">
\mathcal{N}(A)=\left\{x \in \mathbb{R}^{n}: A x=0\right\}</script><h3 id="向量的映射"><a href="#向量的映射" class="headerlink" title="向量的映射"></a>向量的映射</h3><p>向量$y∈\mathbb R^m$ ,其在${\{x_1,…,x_n\}}$的投影是在 ${\{x_1,…,x_n\}}$里面找到向量$v$使得$v$与$y$的欧几里得范数最小，记为</p>
<script type="math/tex; mode=display">
\operatorname{Proj}\left(y ;\left\{x_{1}, \ldots x_{n}\right\}\right)=\operatorname{argmin}_{v \in \operatorname{span}\left(\left\{x_{1}, \ldots, x_{n}\right\}\right)}\|y-v\|_{2}</script><p>且注意：</p>
<p>矩阵A的列空间和零空间共同构成了整个$\mathbb R^m$ </p>
<script type="math/tex; mode=display">
\left\{w: w=u+v, u \in \mathcal{R}\left(A^{T}\right), v \in \mathcal{N}(A)\right\}=\mathbb{R}^{n}$ and $\mathcal{R}\left(A^{T}\right) \cap \mathcal{N}(A)=\emptyset</script><p>且这两部分称为正交补，记为 $\mathcal{R}\left(A^{T}\right)=\mathcal{N}(A)^{\perp}$  </p>
<h2 id="4-行列式性质补充"><a href="#4-行列式性质补充" class="headerlink" title="4.行列式性质补充"></a>4.行列式性质补充</h2><ul>
<li><p>单位矩阵的行列式为1，记为$|I|=1$</p>
</li>
<li><p>矩阵$A∈ \mathbb R^{n×n}$ ，将该矩阵的某一行乘以实数t，则行列式变为原来行列式的t倍。记为$\left|\left[\begin{array}{ccc}{-} &amp; {t a_{1}^{T}} &amp; {-} \ {-} &amp; {a_{2}^{T}} &amp; {-} \ {} &amp; {\vdots} &amp; {} \ {-} &amp; {a_{m}^{T}} &amp; {-}\end{array}\right]\right|=t|A|$ </p>
</li>
<li><p>交换矩阵A的某两行， 行列式变为原来的相反数，记为</p>
<p>$\left|\left[\begin{array}{ccc}{-} &amp; { a_{2}^{T}} &amp; {-} \ {-} &amp; {a_{1}^{T}} &amp; {-} \ {} &amp; {\vdots} &amp; {} \ {-} &amp; {a_{m}^{T}} &amp; {-}\end{array}\right]\right|=-|A|$ </p>
</li>
<li><p>矩阵$A∈  \mathbb R^{n×n}，|A|=|A^T|$</p>
</li>
<li><p>矩阵$A,B∈  \mathbb R^{n×n}，|AB|=|A||B|$</p>
</li>
<li><p>矩阵$A∈  \mathbb R^{n×n}，|A|=0$  当且仅当矩阵是奇异矩阵(或者说当且仅当矩阵A不可逆)</p>
</li>
<li><p>矩阵$A∈  \mathbb R^{n×n}，$矩阵A是非奇异矩阵，$|A^{-1}|=1/|A|$  </p>
</li>
</ul>
<h2 id="5-特征值和特征向量性质补充"><a href="#5-特征值和特征向量性质补充" class="headerlink" title="5.特征值和特征向量性质补充"></a>5.特征值和特征向量性质补充</h2><ul>
<li><p>矩阵A的特征值的和等于矩阵A的迹。记为$trA=\sum_{i=1}^{n} λ_i$ </p>
</li>
<li><p>矩阵A的行列式矩阵A的特征值的乘积。记为$|A|= \prod_{i=1}^{n} λ_{i} $  </p>
</li>
<li><p>矩阵A的秩等于A非零特征向量的个数</p>
</li>
<li><p>若A是非奇异矩阵，则$1/ \lambda _i$是$A^{-1}$ 关于特征向量$x_i$的特征值</p>
</li>
<li><p>对角矩阵D的特征值是对角元素</p>
</li>
<li><p>矩阵与最优化结合的实例应用：</p>
<p>可以将$Ax=λx \quad x≠0$ 写为$AX = X\Lambda $ 其中$X∈\mathbb R^{n×n}$ 是A的特征向量组成的矩阵，V是A矩阵的特征值组成的对角矩阵。且记 $X∈\mathbb R^{n×n}=\left[\begin{array}{cccc}{|} &amp; {|} &amp; {} &amp; {|} \ {x_{1}} &amp; {x_{2}} &amp; {\cdots} &amp; {x_{n}} \ {|} &amp; {|} &amp; {} &amp; {|}\end{array}\right],  \Lambda =diag(λ_1,…,λ_n)$   </p>
<p>若A的特征向量均线性不相关，即矩阵$X$可逆，那么可以写为$A=X\Lambda X^{-1}$ 则称A是可对角化矩阵。</p>
<p>在这里我们防止混淆用$U$表示矩阵的多个特征向量，则$A=U\Lambda U^T$ ,在这里$X^{-1}$ 转变为$U^T$是因为正交矩阵的转秩与正交矩阵的逆相等。则有$x^TAx=x^TU\Lambda U^Tx=y^T\Lambda y=\sum_{i=1}^nλ_iy_i^2$  (U为满秩矩阵，$y∈\mathbb R^n$ 都可以这样表示)且因为$y_i^2$是总是大于0的，所以表达式的正负大小均由λ值决定。</p>
<p>由上述可知特征值和特征向量可以应用在求矩阵乘积最大化问题上：</p>
<script type="math/tex; mode=display">
max_{x∈\mathbb R^{n}}x^TAx        \quad subject \quad to\quad  ||x||_2^2=1</script><p>假设该问题中$λ_1≥λ_2≥…≥λ_n$ 则最合适的x即为特征值$λ_1$对应的特征向量$x_1$ </p>
</li>
</ul>
<h2 id="6-主成分分析"><a href="#6-主成分分析" class="headerlink" title="6.主成分分析"></a>6.主成分分析</h2><h3 id="注意点1："><a href="#注意点1：" class="headerlink" title="注意点1："></a>注意点1：</h3><p><img src="/2019/04/25/math/2.68.png" alt> </p>
<p>2.68-2.69公式推导时省略了一步：</p>
<script type="math/tex; mode=display">
D^{*}=\underset{D}{\arg \min } \sqrt{\sum_{i, j}\left(x_{j}^{(i)}-r\left(x^{(i)}\right)_{j}\right)^{2}}   \ subject \ to  \   D^{\top} D=I_{l}</script><p>与其平方等价：</p>
<script type="math/tex; mode=display">
D^{*}=\underset{D}{\arg \min } {\sum_{i, j}\left(x_{j}^{(i)}-r\left(x^{(i)}\right)_{j}\right)^{2}}   \ subject \ to  \   D^{\top} D=I_{l}</script><p>再将$\sum _{i,j}$ 分为$ \sum_i \sum_j $</p>
<script type="math/tex; mode=display">
D^{*}=\underset{D}{\arg \min } {\sum_{i} \sum_j \left(x_{j}^{(i)}-r\left(x^{(i)}\right)_{j}\right)^{2}}   \ subject \ to  \   D^{\top} D=I_{l}</script><p>又因为将p=2带入(2.30)公式，再将其平方得$||x||_2^2 = \sum_i |x_i|^2 $  同理可整理为</p>
<script type="math/tex; mode=display">
D^{*}=\underset{D}{\arg \min } {\sum_{i} ||x^{(i)}-dd^Tx^{(i)}||_2^2}   \ subject \ to  \   D^{\top} D=I_{l}</script><h3 id="注意点2："><a href="#注意点2：" class="headerlink" title="注意点2："></a>注意点2：</h3><p>2.72式 将$x$转化为$X$中$dd$变为$dd^T$  只是表达形式的转变，并不涉及数学推导。</p>
<h2 id="7-矩阵微分"><a href="#7-矩阵微分" class="headerlink" title="7.矩阵微分"></a>7.矩阵微分</h2><h3 id="矩阵梯度"><a href="#矩阵梯度" class="headerlink" title="矩阵梯度"></a>矩阵梯度</h3><h4 id="基本定义"><a href="#基本定义" class="headerlink" title="基本定义"></a>基本定义</h4><p>设函数$f$对矩阵$A∈\mathbb R^{m×n}$ 有梯度，且$f$函数输入的是m×n的矩阵，输出为一个实数$\mathbb R$，则求出的梯度为与$A$同形的矩阵</p>
<script type="math/tex; mode=display">
\nabla_{A} f(A) \in \mathbb{R}^{m \times n}=\left[\begin{array}{cccc}{\frac{\partial f(A)}{\partial A_{11}}} & {\frac{\partial f(A)}{\partial A_{12}}} & {\cdots} & {\frac{\partial f(A)}{\partial A_{1 n}}} \\ {\frac{\partial f(A)}{\partial A_{21}}} & {\frac{\partial f(A)}{\partial A_{22}}} & {\cdots} & {\frac{\partial f(A)}{\partial A_{2 n}}} \\ {\vdots} & {\vdots} & {\ddots} & {\vdots} \\ {\frac{\partial f(A)}{\partial A_{m 1}}} & {\frac{\partial f(A)}{\partial A_{m 2}}} & {\cdots} & {\frac{\partial f(A)}{\partial A_{m n}}}\end{array}\right]</script><p>即记为$\left(\nabla_{A} f(A)\right)_{i j}=\frac{\partial f(A)}{\partial A_{i j}}$ </p>
<h4 id="性质"><a href="#性质" class="headerlink" title="性质"></a>性质</h4><p>性质1 $\nabla_{x}(f(x)+g(x))=\nabla_{x} f(x)+\nabla_{x} g(x)$<br>性质2 For $t \in \mathbb{R}, \nabla_{x}(t f(x))=t \nabla_{x} f(x)$</p>
<h4 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h4><p>在矩阵表达式中<strong>对谁求梯度一定要写明</strong>，$\nabla_{Ax} f(Ax ) $  是对Ax求梯度，$\nabla_{x} f(Ax) $  则是对x求梯度 </p>
<p>只有当$f(x))$返回值是实数的时候，矩阵的梯度才有定义。</p>
<h3 id="Hessian矩阵"><a href="#Hessian矩阵" class="headerlink" title="Hessian矩阵"></a>Hessian矩阵</h3><p>假设$f$ 是输入为$\mathbb R^n$,输出为实数R的函数，相对于$x$的hessian矩阵就是一个n×n的矩阵</p>
<script type="math/tex; mode=display">
\nabla_{x}^{2} f(x) \in \mathbb{R}^{n \times n}=\left[\begin{array}{cccc}{\frac{\partial^{2} f(x)}{\partial x_{1}^{2}}} & {\frac{\partial^{2} f(x)}{\partial x_{1} \partial x_{2}}} & {\cdots} & {\frac{\partial^{2} f(x)}{\partial x_{1} \partial x_{n}}} \\ {\frac{\partial^{2} f(x)}{\partial x_{2} \partial x_{1}}} & {\frac{\partial^{2} f(x)}{\partial x_{2}^{2}}} & {\cdots} & {\frac{\partial^{2} f(x)}{\partial x_{2} \partial x_{n}}} \\ {\vdots} & {\vdots} & {\ddots} & {\vdots} \\ {\frac{\partial^{2} f(x)}{\partial x_{n} \partial x_{1}}} & {\frac{\partial^{2} f(x)}{\partial x_{n} \partial x_{2}}} & {\cdots} & {\frac{\partial^{2} f(x)}{\partial x_{n}^{2}}}\end{array}\right]</script><p>或者可以写为$\left(\nabla_{x}^{2} f(x)\right)_{i j}=\frac{\partial^{2} f(x)}{\partial x_{i} \partial x_{j}}$ </p>
<h4 id="注意-1"><a href="#注意-1" class="headerlink" title="注意"></a>注意</h4><p>1.因为$\frac{\partial^{2} f(x)}{\partial x_{i} \partial x_{j}}=\frac{\partial^{2} f(x)}{\partial x_{j} \partial x_{i}}$ 所以hessian矩阵是对称矩阵。</p>
<p>2.只有当$f(x))$返回值是实数的时候，hessian矩阵才有定义。</p>
<p>3.若$f$是一个输入为实数，输出为实数的函数，那么根据高等数学知识，</p>
<script type="math/tex; mode=display">
\frac{\partial^{2} f(x)}{\partial x^{2}}=\frac{\partial}{\partial x} \frac{\partial}{\partial x} f(x)在这里如果把$x$换为向量，那么对向量求梯</script><p>在这里如果把$x$换为向量 ，对向量求梯度后大小为n×1，再求梯度还是n×1的，是不等于hessian矩阵(n×n)</p>
<script type="math/tex; mode=display">
\nabla_{x} \nabla_{x} f(x)=\nabla_{x}\left[\begin{array}{c}{\frac{\partial f(x)}{\partial x_{1}}} \\ {\frac{\partial f(x)}{\partial x_{2}}} \\ {\vdots} \\ {\frac{\partial f(x)}{\partial x_{1}}}\end{array}\right]</script><p>所以对向量的梯度求梯度是不等于hessian矩阵的：</p>
<script type="math/tex; mode=display">
\nabla_{x}\left[\begin{array}{c}{\frac{\partial f(x)}{\partial x_{1}}} \\ {\frac{\partial f(x)}{\partial x_{2}}} \\ {\vdots} \\ {\frac{\partial f(x)}{\partial x_{1}}}\end{array}\right]≠ \left[\begin{array}{cccc}{\frac{\partial^{2} f(x)}{\partial x_{1}^{2}}} & {\frac{\partial^{2} f(x)}{\partial x_{1} \partial x_{2}}} & {\cdots} & {\frac{\partial^{2} f(x)}{\partial x_{1} \partial x_{n}}} \\ {\frac{\partial^{2} f(x)}{\partial x_{2} \partial x_{1}}} & {\frac{\partial^{2} f(x)}{\partial x_{2}^{2}}} & {\cdots} & {\frac{\partial^{2} f(x)}{\partial x_{2} \partial x_{n}}} \\ {\vdots} & {\vdots} & {\ddots} & {\vdots} \\ {\frac{\partial^{2} f(x)}{\partial x_{n} \partial x_{1}}} & {\frac{\partial^{2} f(x)}{\partial x_{n} \partial x_{2}}} & {\cdots} & {\frac{\partial^{2} f(x)}{\partial x_{n}^{2}}}\end{array}\right]</script><p><strong>但是</strong>，若将$\left[\begin{array}{c}{\frac{\partial f(x)}{\partial x_{1}}} \ {\frac{\partial f(x)}{\partial x_{2}}} \ {\vdots} \ {\frac{\partial f(x)}{\partial x_{1}}}\end{array}\right]$ 的某一行拿出来对$x$求梯度,则会发现求出来的是hessian矩阵的一列(或一行)：</p>
<script type="math/tex; mode=display">
\nabla_{x} \frac{\partial f(x)}{\partial x_{i}}=\left[\begin{array}{c}{\frac{\partial^{2} f(x)}{\partial x_{i} \partial x_{1}}} \\ {\frac{\partial^{2} f(x)}{\partial x_{i} \partial x_{2}}} \\ {\vdots} \\ {\frac{\partial f(x)}{\partial x_{i} \partial x_{n}}}\end{array}\right]</script><p>因此</p>
<script type="math/tex; mode=display">
\nabla_{x}^{2} f(x)=\left[\nabla_{x}\left(\nabla_{x} f(x)\right)_{1} \quad \nabla_{x}\left(\nabla_{x} f(x)\right)_{2} \quad \cdots \quad \nabla_{x}\left(\nabla_{x} f(x)\right)_{n}\right]</script><p>注意上式为了方便理解可以写为</p>
<script type="math/tex; mode=display">
\nabla_{x}^{2} f(x)=[\nabla_{x} \frac{\partial f(x)}{\partial x_{1}}...\nabla_{x} \frac{\partial f(x)}{\partial x_{i}}...\nabla_{x} \frac{\partial f(x)}{\partial x_{n}}]</script><h4 id="性质-1"><a href="#性质-1" class="headerlink" title="性质"></a>性质</h4><p>性质1 $\nabla_{x} b^{T} x=b$ </p>
<p>性质2 $\nabla_{x} x^{T} A x=2 A x$  (若 $A$ 是对称阵) </p>
<p>性质3$ \nabla_{x}^{2} x^{T} A x=2 A$ (若$A$ 是对称阵)  </p>
<p>【1】：<a href="https://www.mashangxue123.com/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/1399073038.html](https://www.mashangxue123.com/线性代数/1399073038.html" target="_blank" rel="noopener">https://www.mashangxue123.com/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/1399073038.html](https://www.mashangxue123.com/线性代数/1399073038.html</a>)</p>

        </div>
      </div>
    </div>
  </div>
</article>



    <!-- Footer -->
<footer>
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <p class="copyright text-muted">
          Theme By <a target="_blank" href="https://github.com/levblanc">Levblanc.</a>
          Inspired By <a target="_blank" href="https://github.com/klugjo/hexo-theme-clean-blog">Clean Blog.</a>
        </p><p class="copyright text-muted">
          Powered By <a target="_blank" href="https://hexo.io/">Hexo.</a>
        </p>
      </div>
    </div>
  </div>
</footer>


    <!-- After Footer Scripts -->
<script src="/js/highlight.pack.js"></script>
<script>
  document.addEventListener("DOMContentLoaded", function(event) {
    var codeBlocks = Array.prototype.slice.call(document.getElementsByTagName('pre'))
    codeBlocks.forEach(function(block, index) {
      hljs.highlightBlock(block);
    });
  });
</script>

  </body>
</html>

